# Пет проект в области ML/AI



## Цель проекта - реализовать некоторые алгоритмы машинного обучения без использования сторонних библиотек [с полностью самописной математикой](https://github.com/listussr/ML_pet_project/blob/main/Math.h).

## Практическая польза проекта - закрепление на практике фундаментальных принципов построения моделей машинного обучения.

# Что уже реализовано:

* ###  [Класс линейной регресии](https://github.com/listussr/ML_pet_project/blob/main/LinearRegression.h);
* ### [Класс многослойного персептрона](https://github.com/listussr/ML_pet_project/blob/main/NeuralNetwork.h) с произвольным количеством слоёв;
* ### [Класс оптимизатора с алгоритмом обратного распространения ошибки](https://github.com/listussr/ML_pet_project/blob/main/Optimizer.h).

## Кроме того реализованы следующие классы:
* ### [Класс вектора](https://github.com/listussr/ML_pet_project/blob/main/Vector.h). Данный класс задаёт вектор с точки зрения математики. Здесь присутствуют все необходимые перегрузки арифметических операторов, а также некоторые дополнительные методы по типу различных видов нормализации векторов, нахождения матожидания и дисперсии вектора.
* ### [Класс матрицы](https://github.com/listussr/ML_pet_project/blob/main/Matrix.h). Данный класс реализует матрицу на основе класса вектора. Здесь также реализованы необходимые перегрузки арифметических операторов. Кроме того есть методы нахождения определителя и транспонирования матрицы.
* ### [Класс массива](https://github.com/listussr/ML_pet_project/blob/main/Array.h). Обобщённый класс вектора, заточенный уже не только под числа, но и под другие типы данных.
* ### [Класс пары](https://github.com/listussr/ML_pet_project/blob/main/Pair.h). Предназначен для хранения 2 элементов данных с произваольными типами.
* ### [Класс обработчика файлов с расширением .csv](https://github.com/listussr/ML_pet_project/blob/main/CSVHandler.h). Он позволяет открывать файлы с расширением `.csv` и считывать данные в формате `array<array<std::string>>`, т.е. каждый элемент файла будет храниться в отдельной переменной типа `std::string`.
* ### [Классы загрузчиков данных](https://github.com/listussr/ML_pet_project/blob/main/DataLoader.h). Последний из них позволяет загружать в нейронную сеть батчи с данными заданного размера.
* ### [Класс линейного слоя нейронной сети](https://github.com/listussr/ML_pet_project/blob/main/Linear.h). Именно массив объектов этого класса передаётся в конструктор нейронной сети. В этом классе инициализируются веса на каждом слое нейронной сети, а также задаётся функция активации ([реализованы здесь](https://github.com/listussr/ML_pet_project/blob/main/Math.h)).
* ### [Класс логгера](https://github.com/listussr/ML_pet_project/blob/main/Logger.h). Используется для записи конфигурации модели в файл и логирования процесса обучения.

# Какие библиотеки я использовал:
1. ### `<iostream>` - использовалась для доступа к потокам ввода - вывода в консоль;
2. ### `<fstream>` - использовалась в классе `logger` для доступа к потокам ввода - вывода в файл;
3. ### `<cmath>` - для использвания функций `pow()`, `log()`;
4. ### `<ctime>` - для замера времени, уходящего на одну эпоху обучения сети;
5. ### `<string>` - для возможности использовать класс `std::string`;
6. ### `<iomanip>` - для красивого форматирования вывода в консоль;
7. ### `<sstream>` - для разделения строк на слова при чтении `.csv`-файла.
8. ### `<algorithm>` - для использования функции `std::random_shuffle()` при обучении нейронной сети.

# TODO:

1. ### Исправить ошибки, возникающие при обучении нейронной сети в ходе процесса обратного распространения ошибки. В результате них нейронная сеть в задаче классификации сходится к равной вероятности для `n`-классов.
2. ### Реализовать ещё несколько классов оптимизаторов помимо градиентого спуска.
3. ### Начать реализацию классов свёрточной нейронной сети или дерева решений (пока не определился что будет реализовано в первую очередь).
